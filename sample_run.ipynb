{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcof4rSsSU/ORdXs01xokj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishu7989/DATAFLOW-colab/blob/main/sample_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hylo6xR1ExCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d8da328-aa57-4778-c657-6b8548ea6cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.9/676.9 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!{'pip install --quiet apache_beam'}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{'mkdir -p vaishu_colab'}"
      ],
      "metadata": {
        "id": "m91C9vrDIBsU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o80uUy_pITgB",
        "outputId": "ce341df7-9da6-4a07-db89-061262f13e0a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cogroupBy.zip  location.txt  sample_data  vaishu_colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "W6TPv8sUIc9h",
        "outputId": "29578274-ed2c-4ca9-faba-0c20424f82c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-abe30417-e6bc-41cf-8b24-803ce229c0c3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-abe30417-e6bc-41cf-8b24-803ce229c0c3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving location.txt to location.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6RSJYpZI6SR",
        "outputId": "6df88e20-2e6a-4c9f-b596-64de907d30b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cogroupBy.zip  location.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat dept_data.txt"
      ],
      "metadata": {
        "id": "mwP0NCptJDAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating pcollection from your data"
      ],
      "metadata": {
        "id": "RE9cgKIVJXNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "def SplitRow(element):\n",
        "  return element.split(',')\n",
        "def filtering(record):\n",
        "  return record[3] == 'Accounts'\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "attendence_count = (\n",
        "    p1\n",
        "    |beam.io.ReadFromText('dept_data.txt',strip_trailing_newlines = True)\n",
        "    |beam.Map(SplitRow)\n",
        "    |beam.Filter(filtering)\n",
        "    |beam.Map(lambda record: (record[1],1))\n",
        "    #lambda function is the small anonymous fun which can take no.of arguments and gives single argument.\n",
        "    |beam.CombinePerKey(sum)\n",
        "    # CombinePerkey = groupby key + combiner + reducer in argument we can pass some built in functions and as per our requirement.\n",
        "\n",
        "\n",
        "    |beam.io.WriteToText('vaishu_colab/sample_run')\n",
        ")\n",
        "p1.run()\n",
        "\n",
        "#sample the first 20 results,remember there are no ordering guarantees.\n",
        "!{('head -n 20 vaishu_colab/sample_run-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "B91H2waGm-4g",
        "outputId": "fbf23c90-9ac8-41e4-f92e-6a476c48590b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Marco', 31)\n",
            "('Rebekah', 31)\n",
            "('Itoe', 31)\n",
            "('Edouard', 31)\n",
            "('Kyle', 62)\n",
            "('Kumiko', 31)\n",
            "('Gaston', 31)\n",
            "('Ayumi', 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls vaishu_colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZVsrMtenEil",
        "outputId": "fbdf05e0-34a9-4c90-8d7a-a6413487af75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_run-00000-of-00001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat vaishu_colab/sample_run-00000-of-00001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V83nn_m2nIw9",
        "outputId": "4712b4ed-d4d3-4889-dffb-c5585a973414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Marco', 31)\n",
            "('Rebekah', 31)\n",
            "('Itoe', 31)\n",
            "('Edouard', 31)\n",
            "('Kyle', 62)\n",
            "('Kumiko', 31)\n",
            "('Gaston', 31)\n",
            "('Ayumi', 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labeling Transformations providing unique label"
      ],
      "metadata": {
        "id": "riGXJiCknNNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "p2 = beam.Pipeline()\n",
        "\n",
        "ATT_CNT = (\n",
        "    p2\n",
        "    |'Read from file' >> beam.io.ReadFromText('dept_data.txt')\n",
        "    |'Map transform' >> beam.Map(lambda record: record.split(','))\n",
        "    |'Filter transform' >> beam.Filter(lambda record: record[3] == 'Accounts')\n",
        "    |'Transform' >> beam.Map(lambda record: (record[1],1))\n",
        "    |'Combineperkey transform' >> beam.CombinePerKey(sum)\n",
        "    |'Write into file' >> beam.io.WriteToText('vaishu_colab/sample_run_label')\n",
        ")\n",
        "\n",
        "p2.run()\n",
        "\n",
        "!{('head -n 20 vaishu_colab/sample_run_label-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYP92f55nRu0",
        "outputId": "95e38896-929e-44a3-f5d8-340467435404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Marco', 31)\n",
            "('Rebekah', 31)\n",
            "('Itoe', 31)\n",
            "('Edouard', 31)\n",
            "('Kyle', 62)\n",
            "('Kumiko', 31)\n",
            "('Gaston', 31)\n",
            "('Ayumi', 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "with beam.Pipeline() as p3:\n",
        "  count_attendence = (\n",
        "      p3\n",
        "      |'Read from file' >> beam.io.ReadFromText('dept_data.txt')\n",
        "      |'Map transform' >> beam.Map(lambda record: record.split(','))\n",
        "      |'Filter transform' >> beam.Filter(lambda record: record[3] == 'Accounts')\n",
        "      |'Transform' >> beam.Map(lambda record: (record[1],1))\n",
        "      |'Combineperkey transform' >> beam.CombinePerKey(sum)\n",
        "      |'Write into file' >> beam.io.WriteToText('vaishu_colab/sample_run_pipeline_name')\n",
        ")\n",
        "\n",
        "# p3.run()\n",
        "\n",
        "!{('head -n 20 vaishu_colab/sample_run_pipeline_name-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGpBhzOUnWTr",
        "outputId": "f88b88c8-152a-4255-e232-0ed02cfa6d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Marco', 31)\n",
            "('Rebekah', 31)\n",
            "('Itoe', 31)\n",
            "('Edouard', 31)\n",
            "('Kyle', 62)\n",
            "('Kumiko', 31)\n",
            "('Gaston', 31)\n",
            "('Ayumi', 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying same pcollection as input for multiple transforms(branched pipeline)"
      ],
      "metadata": {
        "id": "qPSJpvagoyO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "def SplitRow(element):\n",
        "  return element.split(',')\n",
        "\n",
        "p = beam.Pipeline()\n",
        "\n",
        "input_collection = (\n",
        "    p\n",
        "    |\"read from text file\" >> beam.io.ReadFromText('dept_data.txt')\n",
        "    |\"Split rows\" >> beam.Map(SplitRow)\n",
        "\n",
        ")\n",
        "accounts_count = (\n",
        "    input_collection\n",
        "    |'Get all Accounts dept persons' >> beam.Filter(lambda record: record[3] == 'Accounts')\n",
        "    |'pair each accounts employee with 1' >> beam.Map(lambda record: (\"Account, \" +record[1],1))\n",
        "    |'Group and sum1' >> beam.CombinePerKey(sum)\n",
        "    # |'Write results for account' >> beam.io.WriteToText('vaishu_colab/Account')\n",
        ")\n",
        "\n",
        "hr_count = (\n",
        "    input_collection\n",
        "    | 'Get all HR dept persons' >> beam.Filter(lambda record: record[3] == 'HR')\n",
        "    | 'pair each hr employee with 1' >> beam.Map(lambda record: (\"HR, \" +record[1],1))\n",
        "    | 'Group and sum' >> beam.CombinePerKey(sum)\n",
        "    # | 'Write results for hr' >> beam.io.WriteToText('vaishu_colab/HR')\n",
        "\n",
        ")\n",
        "\n",
        "#new pcollection\n",
        "output = (\n",
        "    (accounts_count,hr_count)\n",
        "    |beam.Flatten()\n",
        "    |beam.io.WriteToText('vaishu_colab/both')\n",
        ")\n",
        "\n",
        "p.run()\n",
        "\n",
        "!{('head -n 20 vaishu_colab/both-00000-of-00001')}\n",
        "\n",
        "# !{('head -n 20 vaishu_colab/Account-00000-of-00001')}\n",
        "\n",
        "# !{('head -n 20 vaishu_colab/HR-00000-of-00001')}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbT7AyGvqC2T",
        "outputId": "9bfc0e2b-e7ff-4bc6-d9e8-70e550040de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Account, Marco', 31)\n",
            "('Account, Rebekah', 31)\n",
            "('Account, Itoe', 31)\n",
            "('Account, Edouard', 31)\n",
            "('Account, Kyle', 62)\n",
            "('Account, Kumiko', 31)\n",
            "('Account, Gaston', 31)\n",
            "('Account, Ayumi', 30)\n",
            "('HR, Beryl', 62)\n",
            "('HR, Olga', 31)\n",
            "('HR, Leslie', 31)\n",
            "('HR, Mindy', 31)\n",
            "('HR, Vicky', 31)\n",
            "('HR, Richard', 31)\n",
            "('HR, Kirk', 31)\n",
            "('HR, Kaori', 31)\n",
            "('HR, Oscar', 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DoFn is a beam class that defines a distributed processing function.\n",
        "#it contains all the logic to run the user provided function parallelly on different machines."
      ],
      "metadata": {
        "id": "TzT00w07MUaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "class SplitRow(beam.DoFn):\n",
        "\n",
        "  def process(self, element):\n",
        "    # return type -> list\n",
        "    return  [element.split(',')]\n",
        "\n",
        "\n",
        "class FilterAccountsEmployee(beam.DoFn):\n",
        "\n",
        "  def process(self, element):\n",
        "    if element[3] == 'Accounts':\n",
        "      return [element]\n",
        "\n",
        "class PairEmployees(beam.DoFn):\n",
        "\n",
        "  def process(self, element):\n",
        "    return [(element[3]+\",\"+element[1], 1)]\n",
        "\n",
        "class Counting(beam.DoFn):\n",
        "\n",
        "  def process(self, element):\n",
        "    # return type -> list\n",
        "    (key, values) = element           # [Marco, Accounts  [1,1,1,1....] , Rebekah, Accounts [1,1,1,1,....] ]\n",
        "    return [(key, sum(values))]\n",
        "\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "attendance_count = (\n",
        "\n",
        "   p1\n",
        "    |beam.io.ReadFromText('dept_data.txt')\n",
        "\n",
        "    |beam.ParDo(SplitRow())\n",
        "   # | 'Compute WordLength' >> beam.ParDo(lambda element: [ element.split(',') ])\n",
        "\n",
        "    |beam.ParDo(FilterAccountsEmployee())\n",
        "    |beam.ParDo(PairEmployees())\n",
        "    | 'Group ' >> beam.GroupByKey()\n",
        "    | 'Sum using ParDo' >> beam.ParDo(Counting())\n",
        "\n",
        "    |beam.io.WriteToText('vaishu_colab/Pardo_trail')\n",
        "\n",
        ")\n",
        "\n",
        "p1.run()\n",
        "\n",
        "# Sample the first 20 results, remember there are no ordering guarantees.\n",
        "!{('head -n 20 vaishu_colab/Pardo_trail-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJE0zLcJM1jD",
        "outputId": "8d146a36-caf5-45c5-9914-1bb4a9d1a30d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Accounts,Marco', 31)\n",
            "('Accounts,Rebekah', 31)\n",
            "('Accounts,Itoe', 31)\n",
            "('Accounts,Edouard', 31)\n",
            "('Accounts,Kyle', 62)\n",
            "('Accounts,Kumiko', 31)\n",
            "('Accounts,Gaston', 31)\n",
            "('Accounts,Ayumi', 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Combiner is a mini reducer which does the reduce task locally to a mapper machine but here in beam it is more than that."
      ],
      "metadata": {
        "id": "06qkRiYSQaPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p = beam.Pipeline()\n",
        "\n",
        "class AverageFn(beam.CombineFn):\n",
        "\n",
        "  def create_accumulator(self):\n",
        "     return (0.0, 0)   # initialize (sum, count)\n",
        "\n",
        "  def add_input(self, sum_count, input):\n",
        "    (sum, count) = sum_count\n",
        "    return sum + input, count + 1\n",
        "\n",
        "  def merge_accumulators(self, accumulators):\n",
        "\n",
        "    ind_sums, ind_counts = zip(*accumulators)       # zip - [(27, 3), (39, 3), (18, 2)]  -->   [(27,39,18), (3,3,2)]\n",
        "    return sum(ind_sums), sum(ind_counts)        # (84,8)\n",
        "\n",
        "  def extract_output(self, sum_count):\n",
        "\n",
        "    (sum, count) = sum_count    # combine globally using CombineFn\n",
        "    return sum / count if count else float('NaN')\n",
        "\n",
        "\n",
        "small_sum = (\n",
        "           p\n",
        "            | beam.Create([15,5,7,7,9,23,13,5])\n",
        "            | \"Combine Globally\" >> beam.CombineGlobally(AverageFn())\n",
        "            | 'Write results' >> beam.io.WriteToText('vaishu_colab/combine')\n",
        "          )\n",
        "p.run()\n",
        "\n",
        "# Sample the first 20 results, remember there are no ordering guarantees.\n",
        "!{'head -n 20 vaishu_colab/combine-00000-of-00001'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRshg1gQQ4fS",
        "outputId": "c6ecd125-c073-4579-f2a4-5935cc7e84a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "class MyTransform(beam.PTransform):\n",
        "\n",
        "  def expand(self, input_coll):\n",
        "\n",
        "    a = (\n",
        "        input_coll\n",
        "                       | 'Group and sum1' >> beam.CombinePerKey(sum)\n",
        "                       | 'count filter accounts' >> beam.Filter(filter_on_count)\n",
        "                       | 'Regular accounts employee' >> beam.Map(format_output)\n",
        "\n",
        "    )\n",
        "    return a\n",
        "\n",
        "def SplitRow(element):\n",
        "    return element.split(',')\n",
        "\n",
        "\n",
        "def filter_on_count(element):\n",
        "  name, count = element\n",
        "  if count > 30:\n",
        "    return element\n",
        "\n",
        "def format_output(element):\n",
        "  name, count = element\n",
        "  return ', '.join((name,str(count),'Regular employee'))\n",
        "\n",
        "p = beam.Pipeline()\n",
        "\n",
        "input_collection = (\n",
        "                      p\n",
        "                      | \"Read from text file\" >> beam.io.ReadFromText('dept_data.txt')\n",
        "                      | \"Split rows\" >> beam.Map(SplitRow)\n",
        "                   )\n",
        "\n",
        "accounts_count = (\n",
        "                      input_collection\n",
        "                      | 'Get all Accounts dept persons' >> beam.Filter(lambda record: record[3] == 'Accounts')\n",
        "                      | 'Pair each accounts employee with 1' >> beam.Map(lambda record: (\"Accounts, \" +record[1], 1))\n",
        "                      | 'composite accoubts' >> MyTransform()\n",
        "                      | 'Write results for account' >> beam.io.WriteToText('vaishu_colab/Account')\n",
        "                 )\n",
        "\n",
        "hr_count = (\n",
        "                input_collection\n",
        "                | 'Get all HR dept persons' >> beam.Filter(lambda record: record[3] == 'HR')\n",
        "                | 'Pair each hr employee with 1' >> beam.Map(lambda record: (\"HR, \" +record[1], 1))\n",
        "                | 'composite HR' >> MyTransform()\n",
        "                | 'Write results for hr' >> beam.io.WriteToText('vaishu_colab/HR')\n",
        "           )\n",
        "p.run()\n",
        "\n",
        "# Sample the first 20 results, remember there are no ordering guarantees.\n",
        "!{('head -n 20 vaishu_colab/Account-00000-of-00001')}\n",
        "!{('head -n 20 vaishu_colab/HR-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQY9DEORUaIO",
        "outputId": "98799ff4-890e-4d61-e1a0-5ac49c065d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accounts, Marco, 31, Regular employee\n",
            "Accounts, Rebekah, 31, Regular employee\n",
            "Accounts, Itoe, 31, Regular employee\n",
            "Accounts, Edouard, 31, Regular employee\n",
            "Accounts, Kyle, 62, Regular employee\n",
            "Accounts, Kumiko, 31, Regular employee\n",
            "Accounts, Gaston, 31, Regular employee\n",
            "HR, Beryl, 62, Regular employee\n",
            "HR, Olga, 31, Regular employee\n",
            "HR, Leslie, 31, Regular employee\n",
            "HR, Mindy, 31, Regular employee\n",
            "HR, Vicky, 31, Regular employee\n",
            "HR, Richard, 31, Regular employee\n",
            "HR, Kirk, 31, Regular employee\n",
            "HR, Kaori, 31, Regular employee\n",
            "HR, Oscar, 31, Regular employee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CogroupBykey\n",
        "#Relational join of two or more key/value Pcollections.\n",
        "#Accepts a dictionary of key/value Pcollections and output a single Pcollection containing 1 key/value tuple for each key in the input Pcollections."
      ],
      "metadata": {
        "id": "CgsgSY9XZMpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMyn1Z0gPagC",
        "outputId": "2623fa68-a621-42c7-cf40-4dac5838bc3a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cogroupBy.zip  dept_data.txt  location.txt  sample_data  vaishu_colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "qZcZvn2_Pov6",
        "outputId": "4d3a3380-219a-4d3e-a7e7-2c752eae4f7c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6657be54-e9c9-4443-8996-0dc8a81efb67\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6657be54-e9c9-4443-8996-0dc8a81efb67\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dept_data.txt to dept_data.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "def retTuple(element):\n",
        "\n",
        "  thisTuple=element.split(',')\n",
        "  return (thisTuple[0],thisTuple[1:])\n",
        "\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "# Apply a ParDo to the PCollection \"words\" to compute lengths for each word.\n",
        "dep_rows = (\n",
        "                p1\n",
        "                | \"Reading File 1\" >> beam.io.ReadFromText('dept_data.txt')\n",
        "                | 'Pair each employee with key' >> beam.Map(retTuple)          # {149633CM : [Marco,10,Accounts,1-01-2019]}\n",
        "\n",
        "               )\n",
        "\n",
        "\n",
        "loc_rows = (\n",
        "                p1\n",
        "                | \"Reading File 2\" >> beam.io.ReadFromText('location.txt')\n",
        "                | 'Pair each loc with key' >> beam.Map(retTuple)                # {149633CM : [9876843261,New York]}\n",
        "               )\n",
        "\n",
        "\n",
        "results = ({'dep_data': dep_rows, 'loc_data': loc_rows}\n",
        "\n",
        "           | beam.CoGroupByKey()\n",
        "           | 'Write results' >> beam.io.WriteToText('data/result')\n",
        "          )\n",
        "\n",
        "\n",
        "p1.run()\n",
        "\n",
        "!{('head -n 20 data/result-00000-of-00001')}"
      ],
      "metadata": {
        "id": "X9OjQVVGZT_4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "cd60c5a9-6695-4ddf-a70f-442dd71c5774"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('149633CM', {'dep_data': [['Marco', '10', 'Accounts', '1-01-2019'], ['Marco', '10', 'Accounts', '2-01-2019'], ['Marco', '10', 'Accounts', '3-01-2019'], ['Marco', '10', 'Accounts', '4-01-2019'], ['Marco', '10', 'Accounts', '5-01-2019'], ['Marco', '10', 'Accounts', '6-01-2019'], ['Marco', '10', 'Accounts', '7-01-2019'], ['Marco', '10', 'Accounts', '8-01-2019'], ['Marco', '10', 'Accounts', '9-01-2019'], ['Marco', '10', 'Accounts', '10-01-2019'], ['Marco', '10', 'Accounts', '11-01-2019'], ['Marco', '10', 'Accounts', '12-01-2019'], ['Marco', '10', 'Accounts', '13-01-2019'], ['Marco', '10', 'Accounts', '14-01-2019'], ['Marco', '10', 'Accounts', '15-01-2019'], ['Marco', '10', 'Accounts', '16-01-2019'], ['Marco', '10', 'Accounts', '17-01-2019'], ['Marco', '10', 'Accounts', '18-01-2019'], ['Marco', '10', 'Accounts', '19-01-2019'], ['Marco', '10', 'Accounts', '20-01-2019'], ['Marco', '10', 'Accounts', '21-01-2019'], ['Marco', '10', 'Accounts', '22-01-2019'], ['Marco', '10', 'Accounts', '23-01-2019'], ['Marco', '10', 'Accounts', '24-01-2019'], ['Marco', '10', 'Accounts', '25-01-2019'], ['Marco', '10', 'Accounts', '26-01-2019'], ['Marco', '10', 'Accounts', '27-01-2019'], ['Marco', '10', 'Accounts', '28-01-2019'], ['Marco', '10', 'Accounts', '29-01-2019'], ['Marco', '10', 'Accounts', '30-01-2019'], ['Marco', '10', 'Accounts', '31-01-2019']], 'loc_data': [['9876843261', 'New York'], ['9204232778', 'New York']]})\n",
            "('212539MU', {'dep_data': [['Rebekah', '10', 'Accounts', '1-01-2019'], ['Rebekah', '10', 'Accounts', '2-01-2019'], ['Rebekah', '10', 'Accounts', '3-01-2019'], ['Rebekah', '10', 'Accounts', '4-01-2019'], ['Rebekah', '10', 'Accounts', '5-01-2019'], ['Rebekah', '10', 'Accounts', '6-01-2019'], ['Rebekah', '10', 'Accounts', '7-01-2019'], ['Rebekah', '10', 'Accounts', '8-01-2019'], ['Rebekah', '10', 'Accounts', '9-01-2019'], ['Rebekah', '10', 'Accounts', '10-01-2019'], ['Rebekah', '10', 'Accounts', '11-01-2019'], ['Rebekah', '10', 'Accounts', '12-01-2019'], ['Rebekah', '10', 'Accounts', '13-01-2019'], ['Rebekah', '10', 'Accounts', '14-01-2019'], ['Rebekah', '10', 'Accounts', '15-01-2019'], ['Rebekah', '10', 'Accounts', '16-01-2019'], ['Rebekah', '10', 'Accounts', '17-01-2019'], ['Rebekah', '10', 'Accounts', '18-01-2019'], ['Rebekah', '10', 'Accounts', '19-01-2019'], ['Rebekah', '10', 'Accounts', '20-01-2019'], ['Rebekah', '10', 'Accounts', '21-01-2019'], ['Rebekah', '10', 'Accounts', '22-01-2019'], ['Rebekah', '10', 'Accounts', '23-01-2019'], ['Rebekah', '10', 'Accounts', '24-01-2019'], ['Rebekah', '10', 'Accounts', '25-01-2019'], ['Rebekah', '10', 'Accounts', '26-01-2019'], ['Rebekah', '10', 'Accounts', '27-01-2019'], ['Rebekah', '10', 'Accounts', '28-01-2019'], ['Rebekah', '10', 'Accounts', '29-01-2019'], ['Rebekah', '10', 'Accounts', '30-01-2019'], ['Rebekah', '10', 'Accounts', '31-01-2019']], 'loc_data': [['9995440673', 'Denver']]})\n",
            "('231555ZZ', {'dep_data': [['Itoe', '10', 'Accounts', '1-01-2019'], ['Itoe', '10', 'Accounts', '2-01-2019'], ['Itoe', '10', 'Accounts', '3-01-2019'], ['Itoe', '10', 'Accounts', '4-01-2019'], ['Itoe', '10', 'Accounts', '5-01-2019'], ['Itoe', '10', 'Accounts', '6-01-2019'], ['Itoe', '10', 'Accounts', '7-01-2019'], ['Itoe', '10', 'Accounts', '8-01-2019'], ['Itoe', '10', 'Accounts', '9-01-2019'], ['Itoe', '10', 'Accounts', '10-01-2019'], ['Itoe', '10', 'Accounts', '11-01-2019'], ['Itoe', '10', 'Accounts', '12-01-2019'], ['Itoe', '10', 'Accounts', '13-01-2019'], ['Itoe', '10', 'Accounts', '14-01-2019'], ['Itoe', '10', 'Accounts', '15-01-2019'], ['Itoe', '10', 'Accounts', '16-01-2019'], ['Itoe', '10', 'Accounts', '17-01-2019'], ['Itoe', '10', 'Accounts', '18-01-2019'], ['Itoe', '10', 'Accounts', '19-01-2019'], ['Itoe', '10', 'Accounts', '20-01-2019'], ['Itoe', '10', 'Accounts', '21-01-2019'], ['Itoe', '10', 'Accounts', '22-01-2019'], ['Itoe', '10', 'Accounts', '23-01-2019'], ['Itoe', '10', 'Accounts', '24-01-2019'], ['Itoe', '10', 'Accounts', '25-01-2019'], ['Itoe', '10', 'Accounts', '26-01-2019'], ['Itoe', '10', 'Accounts', '27-01-2019'], ['Itoe', '10', 'Accounts', '28-01-2019'], ['Itoe', '10', 'Accounts', '29-01-2019'], ['Itoe', '10', 'Accounts', '30-01-2019'], ['Itoe', '10', 'Accounts', '31-01-2019']], 'loc_data': [['9196597290', 'Boston']]})\n",
            "('503996WI', {'dep_data': [['Edouard', '10', 'Accounts', '1-01-2019'], ['Edouard', '10', 'Accounts', '2-01-2019'], ['Edouard', '10', 'Accounts', '3-01-2019'], ['Edouard', '10', 'Accounts', '4-01-2019'], ['Edouard', '10', 'Accounts', '5-01-2019'], ['Edouard', '10', 'Accounts', '6-01-2019'], ['Edouard', '10', 'Accounts', '7-01-2019'], ['Edouard', '10', 'Accounts', '8-01-2019'], ['Edouard', '10', 'Accounts', '9-01-2019'], ['Edouard', '10', 'Accounts', '10-01-2019'], ['Edouard', '10', 'Accounts', '11-01-2019'], ['Edouard', '10', 'Accounts', '12-01-2019'], ['Edouard', '10', 'Accounts', '13-01-2019'], ['Edouard', '10', 'Accounts', '14-01-2019'], ['Edouard', '10', 'Accounts', '15-01-2019'], ['Edouard', '10', 'Accounts', '16-01-2019'], ['Edouard', '10', 'Accounts', '17-01-2019'], ['Edouard', '10', 'Accounts', '18-01-2019'], ['Edouard', '10', 'Accounts', '19-01-2019'], ['Edouard', '10', 'Accounts', '20-01-2019'], ['Edouard', '10', 'Accounts', '21-01-2019'], ['Edouard', '10', 'Accounts', '22-01-2019'], ['Edouard', '10', 'Accounts', '23-01-2019'], ['Edouard', '10', 'Accounts', '24-01-2019'], ['Edouard', '10', 'Accounts', '25-01-2019'], ['Edouard', '10', 'Accounts', '26-01-2019'], ['Edouard', '10', 'Accounts', '27-01-2019'], ['Edouard', '10', 'Accounts', '28-01-2019'], ['Edouard', '10', 'Accounts', '29-01-2019'], ['Edouard', '10', 'Accounts', '30-01-2019'], ['Edouard', '10', 'Accounts', '31-01-2019']], 'loc_data': [['9468234252', 'Miami']]})\n",
            "('704275DC', {'dep_data': [['Kyle', '10', 'Accounts', '1-01-2019'], ['Kyle', '10', 'Accounts', '2-01-2019'], ['Kyle', '10', 'Accounts', '3-01-2019'], ['Kyle', '10', 'Accounts', '4-01-2019'], ['Kyle', '10', 'Accounts', '5-01-2019'], ['Kyle', '10', 'Accounts', '6-01-2019'], ['Kyle', '10', 'Accounts', '7-01-2019'], ['Kyle', '10', 'Accounts', '8-01-2019'], ['Kyle', '10', 'Accounts', '9-01-2019'], ['Kyle', '10', 'Accounts', '10-01-2019'], ['Kyle', '10', 'Accounts', '11-01-2019'], ['Kyle', '10', 'Accounts', '12-01-2019'], ['Kyle', '10', 'Accounts', '13-01-2019'], ['Kyle', '10', 'Accounts', '14-01-2019'], ['Kyle', '10', 'Accounts', '15-01-2019'], ['Kyle', '10', 'Accounts', '16-01-2019'], ['Kyle', '10', 'Accounts', '17-01-2019'], ['Kyle', '10', 'Accounts', '18-01-2019'], ['Kyle', '10', 'Accounts', '19-01-2019'], ['Kyle', '10', 'Accounts', '20-01-2019'], ['Kyle', '10', 'Accounts', '21-01-2019'], ['Kyle', '10', 'Accounts', '22-01-2019'], ['Kyle', '10', 'Accounts', '23-01-2019'], ['Kyle', '10', 'Accounts', '24-01-2019'], ['Kyle', '10', 'Accounts', '25-01-2019'], ['Kyle', '10', 'Accounts', '26-01-2019'], ['Kyle', '10', 'Accounts', '27-01-2019'], ['Kyle', '10', 'Accounts', '28-01-2019'], ['Kyle', '10', 'Accounts', '29-01-2019'], ['Kyle', '10', 'Accounts', '30-01-2019'], ['Kyle', '10', 'Accounts', '31-01-2019']], 'loc_data': [['9776235961', 'Miami']]})\n",
            "('957149WC', {'dep_data': [['Kyle', '10', 'Accounts', '1-01-2019'], ['Kyle', '10', 'Accounts', '2-01-2019'], ['Kyle', '10', 'Accounts', '3-01-2019'], ['Kyle', '10', 'Accounts', '4-01-2019'], ['Kyle', '10', 'Accounts', '5-01-2019'], ['Kyle', '10', 'Accounts', '6-01-2019'], ['Kyle', '10', 'Accounts', '7-01-2019'], ['Kyle', '10', 'Accounts', '8-01-2019'], ['Kyle', '10', 'Accounts', '9-01-2019'], ['Kyle', '10', 'Accounts', '10-01-2019'], ['Kyle', '10', 'Accounts', '11-01-2019'], ['Kyle', '10', 'Accounts', '12-01-2019'], ['Kyle', '10', 'Accounts', '13-01-2019'], ['Kyle', '10', 'Accounts', '14-01-2019'], ['Kyle', '10', 'Accounts', '15-01-2019'], ['Kyle', '10', 'Accounts', '16-01-2019'], ['Kyle', '10', 'Accounts', '17-01-2019'], ['Kyle', '10', 'Accounts', '18-01-2019'], ['Kyle', '10', 'Accounts', '19-01-2019'], ['Kyle', '10', 'Accounts', '20-01-2019'], ['Kyle', '10', 'Accounts', '21-01-2019'], ['Kyle', '10', 'Accounts', '22-01-2019'], ['Kyle', '10', 'Accounts', '23-01-2019'], ['Kyle', '10', 'Accounts', '24-01-2019'], ['Kyle', '10', 'Accounts', '25-01-2019'], ['Kyle', '10', 'Accounts', '26-01-2019'], ['Kyle', '10', 'Accounts', '27-01-2019'], ['Kyle', '10', 'Accounts', '28-01-2019'], ['Kyle', '10', 'Accounts', '29-01-2019'], ['Kyle', '10', 'Accounts', '30-01-2019'], ['Kyle', '10', 'Accounts', '31-01-2019']], 'loc_data': [['9925595092', 'Houston']]})\n",
            "('241316NX', {'dep_data': [['Kumiko', '10', 'Accounts', '1-01-2019'], ['Kumiko', '10', 'Accounts', '2-01-2019'], ['Kumiko', '10', 'Accounts', '3-01-2019'], ['Kumiko', '10', 'Accounts', '4-01-2019'], ['Kumiko', '10', 'Accounts', '5-01-2019'], ['Kumiko', '10', 'Accounts', '6-01-2019'], ['Kumiko', '10', 'Accounts', '7-01-2019'], ['Kumiko', '10', 'Accounts', '8-01-2019'], ['Kumiko', '10', 'Accounts', '9-01-2019'], ['Kumiko', '10', 'Accounts', '10-01-2019'], ['Kumiko', '10', 'Accounts', '11-01-2019'], ['Kumiko', '10', 'Accounts', '12-01-2019'], ['Kumiko', '10', 'Accounts', '13-01-2019'], ['Kumiko', '10', 'Accounts', '14-01-2019'], ['Kumiko', '10', 'Accounts', '15-01-2019'], ['Kumiko', '10', 'Accounts', '16-01-2019'], ['Kumiko', '10', 'Accounts', '17-01-2019'], ['Kumiko', '10', 'Accounts', '18-01-2019'], ['Kumiko', '10', 'Accounts', '19-01-2019'], ['Kumiko', '10', 'Accounts', '20-01-2019'], ['Kumiko', '10', 'Accounts', '21-01-2019'], ['Kumiko', '10', 'Accounts', '22-01-2019'], ['Kumiko', '10', 'Accounts', '23-01-2019'], ['Kumiko', '10', 'Accounts', '24-01-2019'], ['Kumiko', '10', 'Accounts', '25-01-2019'], ['Kumiko', '10', 'Accounts', '26-01-2019'], ['Kumiko', '10', 'Accounts', '27-01-2019'], ['Kumiko', '10', 'Accounts', '28-01-2019'], ['Kumiko', '10', 'Accounts', '29-01-2019'], ['Kumiko', '10', 'Accounts', '30-01-2019'], ['Kumiko', '10', 'Accounts', '31-01-2019']], 'loc_data': [['9837402343', 'Boston']]})\n",
            "('796656IE', {'dep_data': [['Gaston', '10', 'Accounts', '1-01-2019'], ['Gaston', '10', 'Accounts', '2-01-2019'], ['Gaston', '10', 'Accounts', '3-01-2019'], ['Gaston', '10', 'Accounts', '4-01-2019'], ['Gaston', '10', 'Accounts', '5-01-2019'], ['Gaston', '10', 'Accounts', '6-01-2019'], ['Gaston', '10', 'Accounts', '7-01-2019'], ['Gaston', '10', 'Accounts', '8-01-2019'], ['Gaston', '10', 'Accounts', '9-01-2019'], ['Gaston', '10', 'Accounts', '10-01-2019'], ['Gaston', '10', 'Accounts', '11-01-2019'], ['Gaston', '10', 'Accounts', '12-01-2019'], ['Gaston', '10', 'Accounts', '13-01-2019'], ['Gaston', '10', 'Accounts', '14-01-2019'], ['Gaston', '10', 'Accounts', '15-01-2019'], ['Gaston', '10', 'Accounts', '16-01-2019'], ['Gaston', '10', 'Accounts', '17-01-2019'], ['Gaston', '10', 'Accounts', '18-01-2019'], ['Gaston', '10', 'Accounts', '19-01-2019'], ['Gaston', '10', 'Accounts', '20-01-2019'], ['Gaston', '10', 'Accounts', '21-01-2019'], ['Gaston', '10', 'Accounts', '22-01-2019'], ['Gaston', '10', 'Accounts', '23-01-2019'], ['Gaston', '10', 'Accounts', '24-01-2019'], ['Gaston', '10', 'Accounts', '25-01-2019'], ['Gaston', '10', 'Accounts', '26-01-2019'], ['Gaston', '10', 'Accounts', '27-01-2019'], ['Gaston', '10', 'Accounts', '28-01-2019'], ['Gaston', '10', 'Accounts', '29-01-2019'], ['Gaston', '10', 'Accounts', '30-01-2019'], ['Gaston', '10', 'Accounts', '31-01-2019']], 'loc_data': [['9538848876', 'Houston']]})\n",
            "('718737IX', {'dep_data': [['Ayumi', '10', 'Accounts', '2-01-2019'], ['Ayumi', '10', 'Accounts', '3-01-2019'], ['Ayumi', '10', 'Accounts', '4-01-2019'], ['Ayumi', '10', 'Accounts', '5-01-2019'], ['Ayumi', '10', 'Accounts', '6-01-2019'], ['Ayumi', '10', 'Accounts', '7-01-2019'], ['Ayumi', '10', 'Accounts', '8-01-2019'], ['Ayumi', '10', 'Accounts', '9-01-2019'], ['Ayumi', '10', 'Accounts', '10-01-2019'], ['Ayumi', '10', 'Accounts', '11-01-2019'], ['Ayumi', '10', 'Accounts', '12-01-2019'], ['Ayumi', '10', 'Accounts', '13-01-2019'], ['Ayumi', '10', 'Accounts', '14-01-2019'], ['Ayumi', '10', 'Accounts', '15-01-2019'], ['Ayumi', '10', 'Accounts', '16-01-2019'], ['Ayumi', '10', 'Accounts', '17-01-2019'], ['Ayumi', '10', 'Accounts', '18-01-2019'], ['Ayumi', '10', 'Accounts', '19-01-2019'], ['Ayumi', '10', 'Accounts', '20-01-2019'], ['Ayumi', '10', 'Accounts', '21-01-2019'], ['Ayumi', '10', 'Accounts', '22-01-2019'], ['Ayumi', '10', 'Accounts', '23-01-2019'], ['Ayumi', '10', 'Accounts', '24-01-2019'], ['Ayumi', '10', 'Accounts', '25-01-2019'], ['Ayumi', '10', 'Accounts', '26-01-2019'], ['Ayumi', '10', 'Accounts', '27-01-2019'], ['Ayumi', '10', 'Accounts', '28-01-2019'], ['Ayumi', '10', 'Accounts', '29-01-2019'], ['Ayumi', '10', 'Accounts', '30-01-2019'], ['Ayumi', '10', 'Accounts', '31-01-2019']], 'loc_data': [['9204232788', 'Austin']]})\n",
            "('331593PS', {'dep_data': [['Beryl', '20', 'HR', '1-01-2019'], ['Beryl', '20', 'HR', '2-01-2019'], ['Beryl', '20', 'HR', '3-01-2019'], ['Beryl', '20', 'HR', '4-01-2019'], ['Beryl', '20', 'HR', '5-01-2019'], ['Beryl', '20', 'HR', '6-01-2019'], ['Beryl', '20', 'HR', '7-01-2019'], ['Beryl', '20', 'HR', '8-01-2019'], ['Beryl', '20', 'HR', '9-01-2019'], ['Beryl', '20', 'HR', '10-01-2019'], ['Beryl', '20', 'HR', '11-01-2019'], ['Beryl', '20', 'HR', '12-01-2019'], ['Beryl', '20', 'HR', '13-01-2019'], ['Beryl', '20', 'HR', '14-01-2019'], ['Beryl', '20', 'HR', '15-01-2019'], ['Beryl', '20', 'HR', '16-01-2019'], ['Beryl', '20', 'HR', '17-01-2019'], ['Beryl', '20', 'HR', '18-01-2019'], ['Beryl', '20', 'HR', '19-01-2019'], ['Beryl', '20', 'HR', '20-01-2019'], ['Beryl', '20', 'HR', '21-01-2019'], ['Beryl', '20', 'HR', '22-01-2019'], ['Beryl', '20', 'HR', '23-01-2019'], ['Beryl', '20', 'HR', '24-01-2019'], ['Beryl', '20', 'HR', '25-01-2019'], ['Beryl', '20', 'HR', '26-01-2019'], ['Beryl', '20', 'HR', '27-01-2019'], ['Beryl', '20', 'HR', '28-01-2019'], ['Beryl', '20', 'HR', '29-01-2019'], ['Beryl', '20', 'HR', '30-01-2019'], ['Beryl', '20', 'HR', '31-01-2019']], 'loc_data': [['9137216186', 'Miami']]})\n",
            "('560447WH', {'dep_data': [['Olga', '20', 'HR', '1-01-2019'], ['Olga', '20', 'HR', '2-01-2019'], ['Olga', '20', 'HR', '3-01-2019'], ['Olga', '20', 'HR', '4-01-2019'], ['Olga', '20', 'HR', '5-01-2019'], ['Olga', '20', 'HR', '6-01-2019'], ['Olga', '20', 'HR', '7-01-2019'], ['Olga', '20', 'HR', '8-01-2019'], ['Olga', '20', 'HR', '9-01-2019'], ['Olga', '20', 'HR', '10-01-2019'], ['Olga', '20', 'HR', '11-01-2019'], ['Olga', '20', 'HR', '12-01-2019'], ['Olga', '20', 'HR', '13-01-2019'], ['Olga', '20', 'HR', '14-01-2019'], ['Olga', '20', 'HR', '15-01-2019'], ['Olga', '20', 'HR', '16-01-2019'], ['Olga', '20', 'HR', '17-01-2019'], ['Olga', '20', 'HR', '18-01-2019'], ['Olga', '20', 'HR', '19-01-2019'], ['Olga', '20', 'HR', '20-01-2019'], ['Olga', '20', 'HR', '21-01-2019'], ['Olga', '20', 'HR', '22-01-2019'], ['Olga', '20', 'HR', '23-01-2019'], ['Olga', '20', 'HR', '24-01-2019'], ['Olga', '20', 'HR', '25-01-2019'], ['Olga', '20', 'HR', '26-01-2019'], ['Olga', '20', 'HR', '27-01-2019'], ['Olga', '20', 'HR', '28-01-2019'], ['Olga', '20', 'HR', '29-01-2019'], ['Olga', '20', 'HR', '30-01-2019'], ['Olga', '20', 'HR', '31-01-2019']], 'loc_data': [['9708010864', 'Miami']]})\n",
            "('222997TJ', {'dep_data': [['Leslie', '20', 'HR', '1-01-2019'], ['Leslie', '20', 'HR', '2-01-2019'], ['Leslie', '20', 'HR', '3-01-2019'], ['Leslie', '20', 'HR', '4-01-2019'], ['Leslie', '20', 'HR', '5-01-2019'], ['Leslie', '20', 'HR', '6-01-2019'], ['Leslie', '20', 'HR', '7-01-2019'], ['Leslie', '20', 'HR', '8-01-2019'], ['Leslie', '20', 'HR', '9-01-2019'], ['Leslie', '20', 'HR', '10-01-2019'], ['Leslie', '20', 'HR', '11-01-2019'], ['Leslie', '20', 'HR', '12-01-2019'], ['Leslie', '20', 'HR', '13-01-2019'], ['Leslie', '20', 'HR', '14-01-2019'], ['Leslie', '20', 'HR', '15-01-2019'], ['Leslie', '20', 'HR', '16-01-2019'], ['Leslie', '20', 'HR', '17-01-2019'], ['Leslie', '20', 'HR', '18-01-2019'], ['Leslie', '20', 'HR', '19-01-2019'], ['Leslie', '20', 'HR', '20-01-2019'], ['Leslie', '20', 'HR', '21-01-2019'], ['Leslie', '20', 'HR', '22-01-2019'], ['Leslie', '20', 'HR', '23-01-2019'], ['Leslie', '20', 'HR', '24-01-2019'], ['Leslie', '20', 'HR', '25-01-2019'], ['Leslie', '20', 'HR', '26-01-2019'], ['Leslie', '20', 'HR', '27-01-2019'], ['Leslie', '20', 'HR', '28-01-2019'], ['Leslie', '20', 'HR', '29-01-2019'], ['Leslie', '20', 'HR', '30-01-2019'], ['Leslie', '20', 'HR', '31-01-2019']], 'loc_data': [['9410006713', 'Washington']]})\n",
            "('171752SY', {'dep_data': [['Mindy', '20', 'HR', '1-01-2019'], ['Mindy', '20', 'HR', '2-01-2019'], ['Mindy', '20', 'HR', '3-01-2019'], ['Mindy', '20', 'HR', '4-01-2019'], ['Mindy', '20', 'HR', '5-01-2019'], ['Mindy', '20', 'HR', '6-01-2019'], ['Mindy', '20', 'HR', '7-01-2019'], ['Mindy', '20', 'HR', '8-01-2019'], ['Mindy', '20', 'HR', '9-01-2019'], ['Mindy', '20', 'HR', '10-01-2019'], ['Mindy', '20', 'HR', '11-01-2019'], ['Mindy', '20', 'HR', '12-01-2019'], ['Mindy', '20', 'HR', '13-01-2019'], ['Mindy', '20', 'HR', '14-01-2019'], ['Mindy', '20', 'HR', '15-01-2019'], ['Mindy', '20', 'HR', '16-01-2019'], ['Mindy', '20', 'HR', '17-01-2019'], ['Mindy', '20', 'HR', '18-01-2019'], ['Mindy', '20', 'HR', '19-01-2019'], ['Mindy', '20', 'HR', '20-01-2019'], ['Mindy', '20', 'HR', '21-01-2019'], ['Mindy', '20', 'HR', '22-01-2019'], ['Mindy', '20', 'HR', '23-01-2019'], ['Mindy', '20', 'HR', '24-01-2019'], ['Mindy', '20', 'HR', '25-01-2019'], ['Mindy', '20', 'HR', '26-01-2019'], ['Mindy', '20', 'HR', '27-01-2019'], ['Mindy', '20', 'HR', '28-01-2019'], ['Mindy', '20', 'HR', '29-01-2019'], ['Mindy', '20', 'HR', '30-01-2019'], ['Mindy', '20', 'HR', '31-01-2019']], 'loc_data': [['9494683837', 'Boston']]})\n",
            "('153636AS', {'dep_data': [['Vicky', '20', 'HR', '1-01-2019'], ['Vicky', '20', 'HR', '2-01-2019'], ['Vicky', '20', 'HR', '3-01-2019'], ['Vicky', '20', 'HR', '4-01-2019'], ['Vicky', '20', 'HR', '5-01-2019'], ['Vicky', '20', 'HR', '6-01-2019'], ['Vicky', '20', 'HR', '7-01-2019'], ['Vicky', '20', 'HR', '8-01-2019'], ['Vicky', '20', 'HR', '9-01-2019'], ['Vicky', '20', 'HR', '10-01-2019'], ['Vicky', '20', 'HR', '11-01-2019'], ['Vicky', '20', 'HR', '12-01-2019'], ['Vicky', '20', 'HR', '13-01-2019'], ['Vicky', '20', 'HR', '14-01-2019'], ['Vicky', '20', 'HR', '15-01-2019'], ['Vicky', '20', 'HR', '16-01-2019'], ['Vicky', '20', 'HR', '17-01-2019'], ['Vicky', '20', 'HR', '18-01-2019'], ['Vicky', '20', 'HR', '19-01-2019'], ['Vicky', '20', 'HR', '20-01-2019'], ['Vicky', '20', 'HR', '21-01-2019'], ['Vicky', '20', 'HR', '22-01-2019'], ['Vicky', '20', 'HR', '23-01-2019'], ['Vicky', '20', 'HR', '24-01-2019'], ['Vicky', '20', 'HR', '25-01-2019'], ['Vicky', '20', 'HR', '26-01-2019'], ['Vicky', '20', 'HR', '27-01-2019'], ['Vicky', '20', 'HR', '28-01-2019'], ['Vicky', '20', 'HR', '29-01-2019'], ['Vicky', '20', 'HR', '30-01-2019'], ['Vicky', '20', 'HR', '31-01-2019']], 'loc_data': [['9575378417', 'New York']]})\n",
            "('745411HT', {'dep_data': [['Richard', '20', 'HR', '1-01-2019'], ['Richard', '20', 'HR', '2-01-2019'], ['Richard', '20', 'HR', '3-01-2019'], ['Richard', '20', 'HR', '4-01-2019'], ['Richard', '20', 'HR', '5-01-2019'], ['Richard', '20', 'HR', '6-01-2019'], ['Richard', '20', 'HR', '7-01-2019'], ['Richard', '20', 'HR', '8-01-2019'], ['Richard', '20', 'HR', '9-01-2019'], ['Richard', '20', 'HR', '10-01-2019'], ['Richard', '20', 'HR', '11-01-2019'], ['Richard', '20', 'HR', '12-01-2019'], ['Richard', '20', 'HR', '13-01-2019'], ['Richard', '20', 'HR', '14-01-2019'], ['Richard', '20', 'HR', '15-01-2019'], ['Richard', '20', 'HR', '16-01-2019'], ['Richard', '20', 'HR', '17-01-2019'], ['Richard', '20', 'HR', '18-01-2019'], ['Richard', '20', 'HR', '19-01-2019'], ['Richard', '20', 'HR', '20-01-2019'], ['Richard', '20', 'HR', '21-01-2019'], ['Richard', '20', 'HR', '22-01-2019'], ['Richard', '20', 'HR', '23-01-2019'], ['Richard', '20', 'HR', '24-01-2019'], ['Richard', '20', 'HR', '25-01-2019'], ['Richard', '20', 'HR', '26-01-2019'], ['Richard', '20', 'HR', '27-01-2019'], ['Richard', '20', 'HR', '28-01-2019'], ['Richard', '20', 'HR', '29-01-2019'], ['Richard', '20', 'HR', '30-01-2019'], ['Richard', '20', 'HR', '31-01-2019']], 'loc_data': [['9391632080', 'New York']]})\n",
            "('298464HN', {'dep_data': [['Kirk', '20', 'HR', '1-01-2019'], ['Kirk', '20', 'HR', '2-01-2019'], ['Kirk', '20', 'HR', '3-01-2019'], ['Kirk', '20', 'HR', '4-01-2019'], ['Kirk', '20', 'HR', '5-01-2019'], ['Kirk', '20', 'HR', '6-01-2019'], ['Kirk', '20', 'HR', '7-01-2019'], ['Kirk', '20', 'HR', '8-01-2019'], ['Kirk', '20', 'HR', '9-01-2019'], ['Kirk', '20', 'HR', '10-01-2019'], ['Kirk', '20', 'HR', '11-01-2019'], ['Kirk', '20', 'HR', '12-01-2019'], ['Kirk', '20', 'HR', '13-01-2019'], ['Kirk', '20', 'HR', '14-01-2019'], ['Kirk', '20', 'HR', '15-01-2019'], ['Kirk', '20', 'HR', '16-01-2019'], ['Kirk', '20', 'HR', '17-01-2019'], ['Kirk', '20', 'HR', '18-01-2019'], ['Kirk', '20', 'HR', '19-01-2019'], ['Kirk', '20', 'HR', '20-01-2019'], ['Kirk', '20', 'HR', '21-01-2019'], ['Kirk', '20', 'HR', '22-01-2019'], ['Kirk', '20', 'HR', '23-01-2019'], ['Kirk', '20', 'HR', '24-01-2019'], ['Kirk', '20', 'HR', '25-01-2019'], ['Kirk', '20', 'HR', '26-01-2019'], ['Kirk', '20', 'HR', '27-01-2019'], ['Kirk', '20', 'HR', '28-01-2019'], ['Kirk', '20', 'HR', '29-01-2019'], ['Kirk', '20', 'HR', '30-01-2019'], ['Kirk', '20', 'HR', '31-01-2019']], 'loc_data': [['9982641601', 'Miami']]})\n",
            "('783950BW', {'dep_data': [['Kaori', '20', 'HR', '1-01-2019'], ['Kaori', '20', 'HR', '2-01-2019'], ['Kaori', '20', 'HR', '3-01-2019'], ['Kaori', '20', 'HR', '4-01-2019'], ['Kaori', '20', 'HR', '5-01-2019'], ['Kaori', '20', 'HR', '6-01-2019'], ['Kaori', '20', 'HR', '7-01-2019'], ['Kaori', '20', 'HR', '8-01-2019'], ['Kaori', '20', 'HR', '9-01-2019'], ['Kaori', '20', 'HR', '10-01-2019'], ['Kaori', '20', 'HR', '11-01-2019'], ['Kaori', '20', 'HR', '12-01-2019'], ['Kaori', '20', 'HR', '13-01-2019'], ['Kaori', '20', 'HR', '14-01-2019'], ['Kaori', '20', 'HR', '15-01-2019'], ['Kaori', '20', 'HR', '16-01-2019'], ['Kaori', '20', 'HR', '17-01-2019'], ['Kaori', '20', 'HR', '18-01-2019'], ['Kaori', '20', 'HR', '19-01-2019'], ['Kaori', '20', 'HR', '20-01-2019'], ['Kaori', '20', 'HR', '21-01-2019'], ['Kaori', '20', 'HR', '22-01-2019'], ['Kaori', '20', 'HR', '23-01-2019'], ['Kaori', '20', 'HR', '24-01-2019'], ['Kaori', '20', 'HR', '25-01-2019'], ['Kaori', '20', 'HR', '26-01-2019'], ['Kaori', '20', 'HR', '27-01-2019'], ['Kaori', '20', 'HR', '28-01-2019'], ['Kaori', '20', 'HR', '29-01-2019'], ['Kaori', '20', 'HR', '30-01-2019'], ['Kaori', '20', 'HR', '31-01-2019']], 'loc_data': [['9248480224', 'Boston']]})\n",
            "('892691AR', {'dep_data': [['Beryl', '20', 'HR', '1-01-2019'], ['Beryl', '20', 'HR', '2-01-2019'], ['Beryl', '20', 'HR', '3-01-2019'], ['Beryl', '20', 'HR', '4-01-2019'], ['Beryl', '20', 'HR', '5-01-2019'], ['Beryl', '20', 'HR', '6-01-2019'], ['Beryl', '20', 'HR', '7-01-2019'], ['Beryl', '20', 'HR', '8-01-2019'], ['Beryl', '20', 'HR', '9-01-2019'], ['Beryl', '20', 'HR', '10-01-2019'], ['Beryl', '20', 'HR', '11-01-2019'], ['Beryl', '20', 'HR', '12-01-2019'], ['Beryl', '20', 'HR', '13-01-2019'], ['Beryl', '20', 'HR', '14-01-2019'], ['Beryl', '20', 'HR', '15-01-2019'], ['Beryl', '20', 'HR', '16-01-2019'], ['Beryl', '20', 'HR', '17-01-2019'], ['Beryl', '20', 'HR', '18-01-2019'], ['Beryl', '20', 'HR', '19-01-2019'], ['Beryl', '20', 'HR', '20-01-2019'], ['Beryl', '20', 'HR', '21-01-2019'], ['Beryl', '20', 'HR', '22-01-2019'], ['Beryl', '20', 'HR', '23-01-2019'], ['Beryl', '20', 'HR', '24-01-2019'], ['Beryl', '20', 'HR', '25-01-2019'], ['Beryl', '20', 'HR', '26-01-2019'], ['Beryl', '20', 'HR', '27-01-2019'], ['Beryl', '20', 'HR', '28-01-2019'], ['Beryl', '20', 'HR', '29-01-2019'], ['Beryl', '20', 'HR', '30-01-2019'], ['Beryl', '20', 'HR', '31-01-2019']], 'loc_data': [['9723803710', 'New York']]})\n",
            "('245668UZ', {'dep_data': [['Oscar', '20', 'HR', '1-01-2019'], ['Oscar', '20', 'HR', '2-01-2019'], ['Oscar', '20', 'HR', '3-01-2019'], ['Oscar', '20', 'HR', '4-01-2019'], ['Oscar', '20', 'HR', '5-01-2019'], ['Oscar', '20', 'HR', '6-01-2019'], ['Oscar', '20', 'HR', '7-01-2019'], ['Oscar', '20', 'HR', '8-01-2019'], ['Oscar', '20', 'HR', '9-01-2019'], ['Oscar', '20', 'HR', '10-01-2019'], ['Oscar', '20', 'HR', '11-01-2019'], ['Oscar', '20', 'HR', '12-01-2019'], ['Oscar', '20', 'HR', '13-01-2019'], ['Oscar', '20', 'HR', '14-01-2019'], ['Oscar', '20', 'HR', '15-01-2019'], ['Oscar', '20', 'HR', '16-01-2019'], ['Oscar', '20', 'HR', '17-01-2019'], ['Oscar', '20', 'HR', '18-01-2019'], ['Oscar', '20', 'HR', '19-01-2019'], ['Oscar', '20', 'HR', '20-01-2019'], ['Oscar', '20', 'HR', '21-01-2019'], ['Oscar', '20', 'HR', '22-01-2019'], ['Oscar', '20', 'HR', '23-01-2019'], ['Oscar', '20', 'HR', '24-01-2019'], ['Oscar', '20', 'HR', '25-01-2019'], ['Oscar', '20', 'HR', '26-01-2019'], ['Oscar', '20', 'HR', '27-01-2019'], ['Oscar', '20', 'HR', '28-01-2019'], ['Oscar', '20', 'HR', '29-01-2019'], ['Oscar', '20', 'HR', '30-01-2019'], ['Oscar', '20', 'HR', '31-01-2019']], 'loc_data': [['9395037841', 'New York']]})\n",
            "('231206QD', {'dep_data': [['Kumiko', '30', 'Finance', '1-01-2019'], ['Kumiko', '30', 'Finance', '2-01-2019'], ['Kumiko', '30', 'Finance', '3-01-2019'], ['Kumiko', '30', 'Finance', '4-01-2019'], ['Kumiko', '30', 'Finance', '5-01-2019'], ['Kumiko', '30', 'Finance', '6-01-2019'], ['Kumiko', '30', 'Finance', '7-01-2019'], ['Kumiko', '30', 'Finance', '8-01-2019'], ['Kumiko', '30', 'Finance', '9-01-2019'], ['Kumiko', '30', 'Finance', '10-01-2019'], ['Kumiko', '30', 'Finance', '11-01-2019'], ['Kumiko', '30', 'Finance', '12-01-2019'], ['Kumiko', '30', 'Finance', '13-01-2019'], ['Kumiko', '30', 'Finance', '14-01-2019'], ['Kumiko', '30', 'Finance', '15-01-2019'], ['Kumiko', '30', 'Finance', '16-01-2019'], ['Kumiko', '30', 'Finance', '17-01-2019'], ['Kumiko', '30', 'Finance', '18-01-2019'], ['Kumiko', '30', 'Finance', '19-01-2019'], ['Kumiko', '30', 'Finance', '20-01-2019'], ['Kumiko', '30', 'Finance', '21-01-2019'], ['Kumiko', '30', 'Finance', '22-01-2019'], ['Kumiko', '30', 'Finance', '23-01-2019'], ['Kumiko', '30', 'Finance', '24-01-2019'], ['Kumiko', '30', 'Finance', '25-01-2019'], ['Kumiko', '30', 'Finance', '26-01-2019'], ['Kumiko', '30', 'Finance', '27-01-2019'], ['Kumiko', '30', 'Finance', '28-01-2019'], ['Kumiko', '30', 'Finance', '29-01-2019'], ['Kumiko', '30', 'Finance', '30-01-2019'], ['Kumiko', '30', 'Finance', '31-01-2019']], 'loc_data': [['9608996582', 'Chicago']]})\n"
          ]
        }
      ]
    }
  ]
}